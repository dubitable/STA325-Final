---
title: "mike"
output: html_document
---

```{r}
library(MASS)
library(e1071)
library(car)
library(caret)
library(pROC)
library(brant)
library(tidymodels)
library(parsnip)
library(irr)      # for QWK (squared weighted kappa)
library(Metrics)  # for logLoss

source("cleandata.R")
source("eval.R")
source("confusionmatrix.R")
source("partition.R")

# run my own tests. copy pierre but add CV and test with ordinal multinomal logistic regression
# check out interaction terms?

# polr(formula = Diabetes_012 ~ HighBP + HighChol + CholCheck + BMI + HeartDiseaseorAttack + HvyAlcoholConsump + GenHlth + Sex + Age + HighBP: GenHlth, data = train, Hess = TRUE)

# We use threshold-independent metrics (QWK, log loss, MAE, AUC) to select the best model. Then we can use threshold-dependent metrics (ROC, F1, Precision/Recall) to pick the optimal threshold
```

```{r}
diabetes_raw <- read.csv("data/diabetes_012_health_indicators_BRFSS2015.csv")
diabetes <- cleandata(diabetes_raw)
head(diabetes)
```

```{r}
diabetes |> count(Diabetes_012)
```

## EDA

```{r}
diabetes |>
  select(BMI, MentHlth, PhysHlth) |>
  pivot_longer(everything(), names_to = "variable", values_to = "value") |>
  ggplot(aes(x = value)) +
    geom_histogram(bins = 30, fill = "steelblue", color = "white") +
    facet_wrap(~variable, scales = "free")
```

```{r}
diabetes |>
  select(Age, HighBP, HighChol, CholCheck, HeartDiseaseorAttack, HvyAlcoholConsump, GenHlth, Sex) |>
  pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = value)) +
    geom_bar(fill = "steelblue") +
    facet_wrap(~variable, scales = "free")
```

```{r}
cat_vars <- c("Age", "HighBP", "HighChol", "CholCheck", 
              "HeartDiseaseorAttack", "HvyAlcoholConsump", 
              "GenHlth", "Sex")

diabetes %>%
  select(all_of(cat_vars), Diabetes_012) %>%
  pivot_longer(cols = all_of(cat_vars), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = value, fill = Diabetes_012)) +
    geom_bar(position = "fill") +                  # stack normalized to proportions
    scale_y_continuous(labels = scales::percent_format()) +
    facet_wrap(~variable, scales = "free") +
    labs(
      y = "Proportion of Diabetes Categories",
      x = NULL,
      fill = "Diabetes Status",
      title = "Diabetes Proportions by Categorical Variables"
    ) +
    theme_minimal()

```

```{r}
ggplot(diabetes, aes(x = Age, fill = Diabetes_012)) +
  geom_bar(position = "fill") +  # normalized proportions
  labs(y = "Proportion")

```

```{r}
ggplot(diabetes, aes(x = BMI, y = Diabetes_012)) +
  geom_boxplot()
```

```{r}
ggplot(train, aes(x = BMI, y = PhysHlth, color = Diabetes_012)) +
  geom_jitter(height = 0.1, width = 0.1, alpha = 0.5)

```

```{r}
library(corrplot)
num_vars <- diabetes %>% select(BMI, PhysHlth)
corrplot(cor(num_vars), method = "color", type = "upper")
```

```{r}
library(corrplot)
num_vars <- diabetes %>% select(BMI, MentHlth, PhysHlth)
corrplot(cor(num_vars), method = "color", type = "upper")

```

```{r}
ggplot(diabetes, aes(x = BMI, y = Diabetes_012)) +
  geom_boxplot()
```

## Downsampling

```{r}
split <- partition(diabetes, 0.8)
train <- split$train
test <- split$test

train |> count(Diabetes_012)
```

## K-Fold Cross Validation (variety of test metrics)

```{r}
set.seed(123)
folds <- createFolds(train$Diabetes_012, k = 5, list = TRUE)

cv_metrics <- data.frame(
  Fold = numeric(),
  Accuracy = numeric(),
  Balanced_Acc = numeric(),
  QWK = numeric(),
  LogLoss = numeric(),
  MAE = numeric(),
  MacroAUC = numeric()
)

for (i in seq_along(folds)) {
  val_idx <- folds[[i]]
  cv_train <- train[-val_idx, ]
  cv_val   <- train[val_idx, ]

  mod <- polr(Diabetes_012 ~ HighBP + HighChol + CholCheck + BMI +
                HeartDiseaseorAttack + HvyAlcoholConsump + GenHlth +
                Sex + Age + HighBP:GenHlth,
              data = cv_train, Hess = TRUE)

  pred_class <- predict(mod, newdata = cv_val, type = "class")
  pred_probs <- as.data.frame(predict(mod, newdata = cv_val, type = "probs"))
  
  cm <- confusionMatrix(pred_class, cv_val$Diabetes_012)

  cv_metrics <- rbind(cv_metrics, data.frame(
    Fold = i,
    Accuracy = cm$overall["Accuracy"],
    Balanced_Acc = cm$byClass["Balanced Accuracy"],
    QWK = qwk_score(cv_val$Diabetes_012, pred_class),
    LogLoss = log_loss(cv_val$Diabetes_012, pred_probs),
    MAE = mae_ord(cv_val$Diabetes_012, pred_class),
    MacroAUC = macro_auc(cv_val$Diabetes_012, pred_probs)
  ))
}

cv_summary <- cv_metrics |>
  summarise(
    mean_acc = mean(Accuracy),
    mean_bal_acc = mean(Balanced_Acc),
    mean_qwk = mean(QWK, na.rm = TRUE),
    mean_logloss = mean(LogLoss),
    mean_mae = mean(MAE),
    mean_macro_auc = mean(MacroAUC)
  )

cv_summary
```

```{r}

final_polr <- polr(Diabetes_012 ~ HighBP + HighChol + CholCheck + BMI +
                     HeartDiseaseorAttack + HvyAlcoholConsump + GenHlth +
                     Sex + Age + HighBP:GenHlth,
                   data = train, Hess = TRUE)

# class predictions
test_pred_class <- predict(final_polr, newdata = test, type = "class")
confusionMatrix(test_pred_class, test$Diabetes_012)
```

```{r}
# New Evaluations
final_pred_class <- predict(final_polr, newdata = test, type = "class")
final_pred_probs <- as.data.frame(predict(final_polr, newdata = test, type = "probs"))

final_metrics <- list(
  Accuracy = confusionMatrix(final_pred_class, test$Diabetes_012)$overall["Accuracy"],
  Balanced_Acc = confusionMatrix(final_pred_class, test$Diabetes_012)$byClass["Balanced Accuracy"],
  QWK = qwk_score(test$Diabetes_012, final_pred_class),
  LogLoss = log_loss(test$Diabetes_012, final_pred_probs),
  MAE = mae_ord(test$Diabetes_012, final_pred_class),
  MacroAUC = macro_auc(test$Diabetes_012, final_pred_probs)
)

final_metrics
```

```{r}
test_probs <- as.data.frame(predict(final_polr, newdata = test, type = "probs"))

roc_no  <- roc(ifelse(test$Diabetes_012=="NoDiabetes",1,0),  test_probs$NoDiabetes,   quiet=TRUE)
roc_pre <- roc(ifelse(test$Diabetes_012=="PreDiabetes",1,0), test_probs$PreDiabetes,  quiet=TRUE)
roc_dia <- roc(ifelse(test$Diabetes_012=="Diabetes",1,0),    test_probs$Diabetes,     quiet=TRUE)

plot(roc_no,  col="blue",   main="One‑vs‑Rest ROC Curves", legacy.axes=TRUE)
plot(roc_pre, col="orange", add=TRUE)
plot(roc_dia, col="red",    add=TRUE)
legend("bottomright",
       legend=c("NoDiabetes","PreDiabetes","Diabetes"),
       col=c("blue","orange","red"), lwd=2)

print(pROC::auc(roc_no))
print(pROC::auc(roc_pre))
print(pROC::auc(roc_dia))
```

```{r}
brant(final_polr)
```

## Transformation EDA

```{r}
# Make transformed columns

train <- train %>%
mutate(
BMI_log = log(BMI),
BMI_sqrt = sqrt(BMI)
)

test <- test %>%
mutate(
BMI_log = log(BMI),
BMI_sqrt = sqrt(BMI)
)

# Function to fit polr model and get metrics

evaluate_polr <- function(train_df, test_df, bmi_var) {
formula <- as.formula(paste(
"Diabetes_012 ~ HighBP + HighChol + CholCheck +",
bmi_var,
"+ HeartDiseaseorAttack + HvyAlcoholConsump + GenHlth + Sex + Age + HighBP:GenHlth"
))

mod <- polr(formula, data = train_df, Hess = TRUE)

pred_class <- predict(mod, newdata = test_df, type = "class")
pred_probs <- as.data.frame(predict(mod, newdata = test_df, type = "probs"))

metrics <- list(
Accuracy = confusionMatrix(pred_class, test_df$Diabetes_012)$overall["Accuracy"],
Balanced_Acc = confusionMatrix(pred_class, test_df$Diabetes_012)$byClass["Balanced Accuracy"],
QWK = qwk_score(test_df$Diabetes_012, pred_class),
LogLoss = log_loss(test_df$Diabetes_012, pred_probs),
MAE = mae_ord(test_df$Diabetes_012, pred_class),
MacroAUC = macro_auc(test_df$Diabetes_012, pred_probs)
)

return(metrics)
}

# Evaluate original BMI, log(BMI), and sqrt(BMI)

metrics_orig <- evaluate_polr(train, test, "BMI")
metrics_log  <- evaluate_polr(train, test, "BMI_log")
metrics_sqrt <- evaluate_polr(train, test, "BMI_sqrt")

metrics_orig
metrics_log
metrics_sqrt
```

```{r}

# Combine the metrics into a single data frame
results <- tibble(
  Model = c("BMI", "log(BMI)", "sqrt(BMI)"),
  Accuracy = c(metrics_orig$Accuracy, metrics_log$Accuracy, metrics_sqrt$Accuracy),
  Balanced_Acc = c(metrics_orig$Balanced_Acc, metrics_log$Balanced_Acc, metrics_sqrt$Balanced_Acc),
  QWK = c(metrics_orig$QWK, metrics_log$QWK, metrics_sqrt$QWK),
  LogLoss = c(metrics_orig$LogLoss, metrics_log$LogLoss, metrics_sqrt$LogLoss),
  MAE = c(metrics_orig$MAE, metrics_log$MAE, metrics_sqrt$MAE),
  MacroAUC = c(metrics_orig$MacroAUC, metrics_log$MacroAUC, metrics_sqrt$MacroAUC)
)

# Print nicely
results

```

```{r}

library(patchwork)  # for combining plots

p1 <- ggplot(diabetes, aes(x = BMI)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of BMI (before downsampling)",
    x = "BMI",
    y = "Count"
  ) +
  theme_minimal()

p2 <- ggplot(train, aes(x = BMI)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of BMI (after downsampling)",
    x = "BMI",
    y = "Count"
  ) +
  theme_minimal()

# Display
p1 / p2
```

```{r}
a1 <- ggplot(diabetes, aes(x = MentHlth)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of MentHlth (before downsampling)",
    x = "MentHlth",
    y = "Count"
  ) +
  theme_minimal()

a2 <- ggplot(diabetes, aes(x = PhysHlth)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(
    title = "Distribution of PhysHlth (before downsampling)",
    x = "PhysHlth",
    y = "Count"
  ) +
  theme_minimal()

a1 / a2
```
